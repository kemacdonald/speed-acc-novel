# load libraries
library(reshape); library(plyr); library(grid)
library(lme4); library(knitr)
library(XML); library(gridExtra)
library(magrittr); #library(langcog); 
library(stringr); library(arm)
library(directlabels); library(lazyeval) 
library(forcats); library(RWiener)
library(GGally); library(lsr)
library(effsize); library(cowplot)
library(scales); library(feather) 
library(stringr); library(pryr)
library(rstanarm);

# load tidyverse last, so no functions get masked
library(tidyverse); 

aggregate_ss_looking <- function(df, grouping_cols, aoi_column) {
  # create group by to get the total number of looks in each time slice
  total_looks_group_by <- rlang::syms(grouping_cols)
  
  # add aoi looking column to group by to get the total number of looks to an AOI in a timeslice
  aoi_looks_group_by <- rlang::syms(c(grouping_cols, aoi_column))
  
  ss_total <- df %>% 
    count(!!! total_looks_group_by) %>% 
    complete(!!! total_looks_group_by, fill = list(n = 0)) %>% 
    rename(n_total_looks = n)
  
  ss_aois <- df %>%
    count(!!! aoi_looks_group_by) %>%
    complete(!!! aoi_looks_group_by, fill = list(n = 0)) %>%
    rename(n_aoi_looks = n)
  
  left_join(ss_aois, ss_total) %>%
    mutate(prop_looking = n_aoi_looks / n_total_looks) %>% 
    filter(!is.nan(prop_looking))
  
}

create_time_bin_trial <- function(trial, t_ms_diff = 33) {
  n_bins <- nrow(trial)
  max_time <- trial$t_rel_noun %>% max() * 1000
  time_ms <- seq.int(0, max_time, by = t_ms_diff %>% round()) %>% .[1:n_bins]
  
  trial %>% 
    mutate(time_ms_normalized = time_ms ,
           time_bin = seq.int(1, n_bins))
}

create_time_bins_ss <- function(ss_df, t_ms_diff = 33) {
  ss_df %>% 
    split(.$trial_num_exp) %>% 
    purrr::map_dfr(create_time_bin_trial, t_ms_diff)
}

process_log_files <- function(dir_path) {
  files <- list.files(dir_path)
  files %>% purrr::map_dfr(process_log_file, file_path = dir_path)
}

process_log_file <- function(file, file_path) {
  # get order age and name from log file name
  order_age <- str_split(file, "-", simplify = T)[3] %>% str_replace(".xml", "")
  order_name <- str_split(file, "-", simplify = T)[4] %>% str_replace(".xml", "")
  xml_list <- xmlParse(here::here(file_path, file)) %>% xmlToList(simplify = TRUE)
  xml_list %>% purrr::map_dfr(make_stimulus_key, order_name, order_age)
}

make_stimulus_key <- function(xml_obj, order_name, order_age) {
  is_stimulus_file <- (str_detect(names(xml_obj), pattern = "StimulusFile") %>% sum()) > 0
  
  if(is_stimulus_file) {
    d <- tibble(
      stimulus_name = xml_obj[["Name"]],
      stimulus = xml_obj[["StimulusFile"]],
      stimulus_type = xml_obj[["Type"]]
    )
  } else {
    d <- tibble(
      stimulus_name = xml_obj[["Name"]],
      stimulus = NA,
      stimulus_type = xml_obj[["Type"]]
    )
  }
  
  d %>% mutate(stimulus_name = str_remove(stimulus_name, ".mov|.jpg|.png|.avi"),
               order_name = str_remove(order_name, "_[:digit:]+"),
               order_age = order_age,
               trial_num_exp = str_extract(stimulus_name, pattern = "[:digit:]+"),
               stimulus_name = str_remove_all(stimulus_name, pattern = '_*[:digit:]+'),
               stimulus_name = str_remove(stimulus_name, pattern = '[.]'),
               stimulus_name = str_trim(stimulus_name),
               stimulus = str_remove(stimulus, ".mov|.jpg|.png|.avi")) 
}

to.n <- function (x) {
  as.numeric(as.character(x))
}

# convert xml object to stimuli key-value pairs
make_stim_key_value_pairs <- function(xml_obj) {
  tibble(
    key = xml_obj[['GUID']],
    name = xml_obj[['Name']]
  )
}

# note that we flip the y coordinate 
process_one_stim_xml <- function(xml_obj, x_max = 1920, y_max = 1080, file_name) {
  print(file_name)
  tibble(
    stimulus = str_remove(file_name, pattern = ".xml"),
    stimulus_name = xml_obj$Tag,
    aoi_x_min = xml_obj[['Points']][[1]]$X,
    aoi_y_min = y_max - as.numeric(xml_obj[['Points']][[2]]$Y),
    aoi_x_max = xml_obj[['Points']][[2]]$X,
    aoi_y_max = y_max - as.numeric(xml_obj[['Points']][[1]]$Y)
  ) %>% 
    mutate(aoi_type = ifelse(str_detect(stimulus_name, ".jpg|.png"), "image", "movie"),
           aoi_location = case_when (
             aoi_x_min == 0 ~ 'left',
             aoi_y_max == 1080 ~ 'center_face',
             aoi_x_max == x_max ~ 'right'
           ))
} 

make_roi_key_value_pairs <- function(file, x_max = 1920, y_max = 1080) {
  xml_list <- xmlParse(here::here(read_path, file)) %>% xmlToList()
  xml_list %>% purrr::map_dfr(process_one_stim_xml, x_max = x_max, y_max = y_max, file_name = file)
}

# convert logit to probability 
logit_to_prob <- function(logit) {
  odds <- exp(logit)
  odds / (1 + odds)
}

## Read HDDM file
read_hddm_file <- function(file_name, path, condition_list, param_list) {
  raw_file <- read_csv(paste0(path, file_name), col_names = F)
  
  # get condition and param name from the file name
  condition_name <- str_extract(string = file_name, pattern = paste(condition_list, collapse = '|'))
  param_name <- str_extract(string = file_name, pattern = paste(param_list, collapse = '|'))
  
  final_df <- t(raw_file) %>% 
    as.data.frame() %>% 
    rename(param_value = V1) %>% 
    mutate(condition = condition_name,
           param_name = param_name)
  
  final_df
}

## Plot HDDM parameter values
plot_hddm <- function(d, x_lims = c(0, 3)) {
  ggplot(aes(x = param_value, color = condition), data = d) +
    geom_line(stat="density", size = 1.5) + 
    langcog::scale_color_solarized() +
    facet_grid(.~param_name, scales = "free") +
    labs(x = "Parameter value", y = "Density", color = "") +
    guides(color=guide_legend(nrow=2,byrow=TRUE)) +
    ggthemes::theme_few() +
    lims(x = x_lims) +
    theme(text = element_text(size=10),
          legend.position=c(0.75,0.75),
          legend.direction="horizontal",
          legend.background = element_rect(fill=alpha('white', 0.4)))
}

## Score trial function
## Categorizes trials as correct or incorrect in 2-AFC gaze task
## Takes in a row (trial), a start window, and an end window
## Returns whether that trial was a correct or incorrect shift

score_trial_type_lwl <- function(trial, start, end) { 
  start_col <- which(names(trial)==start)
  end_col <- which(names(trial)==end)
  trial_type <- "no_shift"
  rt <- NA
  response <- trial[which(names(trial)=="Response")]
  first_look_signer <- FALSE
  
  if (response == "D") {
    for (col in start_col:end_col) {
      prev_val <- trial[col-1]
      curr_val <- trial[col]
      next_val <- trial[col+1]
      
      if(is.na(curr_val)) { # break if we hit an NA
        break
      } 
      
      if(first_look_signer) {
        
        if(curr_val == "." & prev_val == "0.5") {rt <- names(trial[col])} # store RT
        
        if(curr_val == "." & next_val %in% c("0", "1", "0.5", ".5")) {
          if(next_val == "1") {
            trial_type <- "C_T"
          } else if(next_val == "0.5" | next_val == ".5") {
            trial_type <- "C_C"
          } else {
            trial_type <- "C_D"    
          }
          break
        }
      } else {
        ## check if current value is look to signer
        ## if it is then we should start checking for trial_type
        if(curr_val %in% c("0.5", ".5")) {
          first_look_signer <- TRUE
        }
      }
    }
  } else {
    trial_type <- "off_center"
  }
  
  c(trial_type, rt)
}

## Add trial numbers 
## Takes a participant's data frame and number of trials for each participant
## Returns the df with trial numbers added
add.tr.nums.fun <- function (df) {
  
  n_trials <- df %>% 
    select(subid, stimulus) %>% 
    unique() %>% 
    nrow()
  
  df %<>% select(subid, stimulus, t) %>% 
    arrange(t) %>% 
    select(subid, stimulus) %>% 
    unique() %>% 
    mutate(tr.num = 1:n_trials)
  
  df
}

## Score trial for SMI eye tracking data
## Takes in a data frame for each trial and 
## Returns (1) an RT and (2) whether the shift was correct vs. incorrect

score_trial_et <- function(trial_df, crit_onset_type = "noun") {
  # filter trial to keep just that onset type
  trial_df %<>% filter(response_onset_type == crit_onset_type)
  # print the subid and trial number to make debugging easier
  print(paste(trial_df$trial_num_exp[1], trial_df$subid[1]))
  
  # build variables to index each trial
  response_type_index <- paste0(crit_onset_type, "_onset") 
  t_filter_type <- paste0("t_rel_", crit_onset_type, " > 0")
  t_select_type <- paste0("t_rel_", crit_onset_type)
  
  # check if there is a shift in the trial after the critical onset
  # and record where the shift started and ended
  crit_window_responses <- trial_df %>% 
    filter_(t_filter_type) %>% 
    select_("target_looking", t_select_type) %>% 
    group_by(target_looking) %>% 
    summarise_(min_t = interp(~ min(x), x = as.name(t_select_type))) %>% 
    arrange(min_t)
  
  # store info about the shift
  shift_start <- crit_window_responses$target_looking[1]
  shift_info <-paste(crit_window_responses$target_looking[1], crit_window_responses$target_looking[2],
                     sep = "-")
  
  # check if there is only one "response" in the target_looking vector
  # if 1, then there was no shift (i_e_, no change from response at crit_onset)
  if (nrow(crit_window_responses) == 1) {
    trial_score <- trial_df %>% 
      mutate(rt = NA, shift_type = "no_shift") %>% 
      select(rt, shift_type) 
  } else {
    # get the earliest time point when target looking switches from the critical onset value 
    trial_score <- trial_df %>% 
      filter_(t_filter_type) %>% 
      filter(target_looking != shift_start) %>% 
      select_(t_select_type, "target_looking") %>% 
      group_by(target_looking) %>% 
      summarise_(rt = interp(~ min(x), x = as.name(t_select_type))) %>% 
      filter(rt == min(rt)) %>% 
      mutate(shift_type = ifelse(shift_info == "center-target", "C_T", 
                                 ifelse(shift_info == "center-distracter", "C_D",
                                        ifelse(shift_info == "target-distracter", "T_D",
                                               ifelse(shift_info== "target-center", "T_C",
                                                      ifelse(shift_info == "distracter-target", "D_T",
                                                             ifelse(shift_info == "distracter-center", "D_C", NA)))))),
             shift_accuracy = ifelse(shift_type == "C_T", "correct", "incorrect")) %>%
      select(rt, shift_type, shift_accuracy) 
  }
  
  # add the rt and score to the trial data frame
  cbind(trial_df, trial_score)
}


## Fit DDM function 
## Takes in a data frame that has been split by participant and condition
## Returns a data frame of DDM parameter values for that participant/condition
## Note that if the participant does not have any valid RTs, then it returns NAs for DDM vals

fit_ddm <- function(df, condition_col, subid_col, bysub = T, niter = 500) {
  # get the condition and subid values
  cond <- unique(df[[condition_col]])
  sub <- unique(df[[subid_col]])
  param_names <- c("separation", "non.decision", "bias", "drift")
  df %<>% 
    select(q, resp) %>% 
    as.data.frame()
  # fit ddm if there are valid responses to fit
  if (nrow(df) > 0) {
    # fit ddm for each participant 
    fit.vals <- optim(c(1, .1, .1, 1), wiener_deviance, control = list(maxit = niter),
                      dat=df, method="Nelder-Mead")
    pars <- cbind(data.frame(fit.vals = fit.vals$par), param = param_names, convergence = fit.vals$convergence) 
  } else {
    pars <- cbind(data.frame(fit.vals = c(NA, NA, NA, NA)), param = param_names, convergence = NA)
  }
  
  # add info to the sub_df and return
  if (bysub == T) {
    pars %<>% 
      mutate(subid = sub, condition = cond,
             fit.vals = round(fit.vals, 3))
  } else {
    pars %<>% 
      mutate(condition = cond, 
             fit.vals = round(fit.vals, 3))
  }
  
  pars
}

## Remove outlier values
## takes in a data frame for an experimental condition, a stdev cutpoint, and a column name to compute over
## returns that data frame with extreme values +/- stdev cutpoint from the mean for that condition

remove_extreme_vals <- function(data_frame, sd_cut_val = 2, value_column) {
  m.val <- mean(data_frame[[value_column]])
  sd.val <- sd(data_frame[[value_column]])
  # compute cut points
  cut_point_upper <- round(m.val + (sd_cut_val * sd.val), 3)
  cut_point_lower <- round(m.val - (sd_cut_val * sd.val), 3)
  
  # standard eval stuff
  filter_criteria_upper <- interp(~y <= x, .values=list(y = as.name(value_column), x = cut_point_upper))
  filter_criteria_lower <- interp(~y >= x, .values=list(y = as.name(value_column), x = cut_point_lower))
  
  # filter and return df
  data_frame %<>% 
    mutate(cut_point_upper = cut_point_upper,
           cut_point_lower = cut_point_lower) %>% 
    filter_(filter_criteria_upper, 
            filter_criteria_lower)
  
  data_frame
}


################################################################################
## IDF CONVERT
## read in data file from SMI tracker's IDF converter utility
## major issue is that new stimuli are marked as new "events" 
## need to be converted to their own column
##
## adapted from aen and dy
################################################################################

process_et_file <- function(file_name, file_path, x_max = 1920, y_max = 1080, avg_eyes=TRUE, sample_rate = 30) {
  d <- read.smi.idf(paste(file_path, file_name, sep="")) 
  preprocess.data(d, x.max = x_max, y.max = y_max, samp.rate = sample_rate, avg.eyes = avg_eyes) 
}

read.smi.idf <- function (file.name, suffix.len = 4) {
  print(file.name)
  
  ## read the header from the file to paste back into the new file
  tmp.header <- scan(file.name, what = character(), sep="\n", 
                     nlines = 40, quiet=TRUE)
  
  ## trim to just contain header information 
  header <- vector()
  for(index in 1:length(tmp.header)) {
    line <- tmp.header[index]
    header <- c(header, line)
    if (line == "## ") {break}
  }
  
  ## get subject id from the header
  subid <- header[str_detect(header, "Subject")]
  subid <- str_split(subid, pattern = "\t")[[1]][2]
  
  ## get the length of the header so we know how many rows to skip before reading the data
  header.rows <- length(header)
  
  ## DATA CLEANING 
  # read in data and get rid of header rows
  all.d <- read_tsv(file.name, skip = header.rows, col_types = cols(Time = "c"))
  
  ## split data into messages and data
  ## First get data:
  d <- all.d %>% filter(all.d$Type=="SMP")
  
  # convert to numeric here
  d$rx <- to.n(d$"R POR X [px]")
  d$ly <- to.n(d$"L POR Y [px]")
  d$ry <- to.n(d$"R POR Y [px]")
  d$lx <- to.n(d$"L POR X [px]") 
  
  #clean up data frame
  d %<>% 
    select(Time, lx, ly, rx, ry) %>%
    rename(t = Time) %>% 
    mutate(t = to.n(t))
  
  ## Now get "messages" - about the stimulus that's being presented
  all.d$rawx <- all.d$"L Raw X [px]"
  
  msgs <- all.d %>% 
    filter(Type=="MSG") %>%
    select(Time, rawx) %>%
    rename(t = Time,
           msg = rawx) %>%
    mutate(stimulus = gsub("# Message: ", "",msg),
           t = to.n(t))
  
  ## merge stimulus information back into d frame as a column
  d$stimulus <- sapply(d$t,
                       function(x) {
                         set <- msgs$stimulus[msgs$t < x]
                         set[length(set)]
                       })
  
  d$stimulus <- as.character(d$stimulus)
  
  ## drop the times before the first video
  d %<>% filter(stimulus != "character(0)") 
  
  ## add subid
  d$subid <- subid
  
  return(d)
}

################################################################################
## PREPROCESS DATA 
## take data file with l and r, x and y, as well as stimulus, average
## eyes, do whatever preprocessing needs to be done. 
################################################################################

preprocess.data <- function(d, x.max = 1920, y.max=1080,
                            samp.rate = 30,
                            avg.eyes=TRUE) {
  
  ## drop the .jpg from the stimulus
  ##d$stimulus <- str_replace(d$stimulus,pattern=".jpg",replacement="")
  
  # remove bad looks before averaging the eyes
  d %<>%
    mutate(rx = ifelse(rx < 1 | rx > 1919, NA, rx),
           lx = ifelse(lx < 1 | lx > 1919, NA, lx),
           ry = ifelse(ry < 1 | ry > 1079, NA, ry),
           ly = ifelse(ly < 1 | ly > 1079, NA, ly))
  
  ## average the eyes
  if (avg.eyes) {
    # if we have both eyes, then average to the nearest pixel
    # if one of the eyes is missing, then just use the other eye's coordinate
    d %<>%
      mutate(x = ifelse(!is.na(rx) & !is.na(lx), (lx+rx) / 2,
                        ifelse(is.na(rx) & !is.na(lx), lx, 
                               ifelse(is.na(lx) & !is.na(rx), rx, 
                                      NA))),
             y = ifelse(!is.na(ry) & !is.na(ly), (ly+ry) / 2,
                        ifelse(is.na(ry), ly, 
                               ifelse(is.na(ly), ry, 
                                      NA)))
      )
    
    # remove the l/r eye variable names
    d <- d[, !(names(d) %in% c("lx","rx","ly","ry"))]
  }
  
  ## clip off out of range numbers
  d$x[d$x < 0 | d$x > x.max] <- NA
  d$y[d$y < 0 | d$y > y.max] <- NA
  
  ## convert the time into seconds
  d$t <- round((d$t - d$t[1])/(1000000), 3)
  ms.increment <- c(0, diff(d$t))
  
  ## add a column of times for each video segment
  ## note this code makes me somewhat ashamed; it's slow and it abuses the R namespace
  ## because it's basically a for loop. but I don't know how to fix it. -mcf
  stim.change <- c(diff(as.numeric(factor(d$stimulus))) != 0,0)
  dt <- c(diff(d$t),0)
  t <- 0
  d$t.stim <- mapply(function (x,y) { 
    if(x==TRUE) { # if stimulus changes
      t <<- 0 # reset counter
      return(t)
    } else { # if stimulus is the same
      t <<- t + y # increment counter
      return(t)
    }},stim.change,dt)
  
  ## round to the nearest sample
  d$t.stim <- round(d$t.stim*samp.rate)/samp.rate
  
  ## y flip (so origin is cartesian, not matrix (bottom left, instead of top left)
  d$y <- y.max - d$y
  
  ## finished
  return (d)
}

################################################################################
## ROI CHECK
## takes a list of ROIs as x, y, w, h boxes
## returns ROI number or NAN
################################################################################

roi.check <- function (d, rois) {
  roi <- factor(NA,levels=names(rois))
  
  for (i in 1:length(rois)) {
    r <- rois[[i]]
    roi[d$x > r[1] & d$x < r[1] + r[3] &
          d$y > r[2] & d$y < r[2] + r[4]] <- names(rois)[i]
  }
  
  return(roi)
}

################################################################################
## REZERO TRIALS
## create timestamps starting from the point of disambiguation
################################################################################

rezero.trials <- function (d,onset.name="target.onset") {
  ddply(d,.(stimulus,subid), function(x) {
    x$t.crit <- x$t.stim - x[,onset.name]
    return(x)
  })
}

################################################################################
## ROI IMAGE1
## takes a list of ROIs as x, y, w, h boxes
## makes a picture so you can check them
################################################################################

roi.image <- function (rois,y.max=1050,x.max=1680) {
  plot(NA,xlim=c(0,x.max),ylim=c(0,y.max),bty="n",xlab="x",ylab="y")
  
  for (i in 1:length(rois)) {
    r <- rois[[i]]
    rect(r[1], r[2], r[1] + r[3], r[2] + r[4])
    text(r[1] + r[3]/2,
         r[2] + r[4]/2,
         names(rois)[i])
  }
}
